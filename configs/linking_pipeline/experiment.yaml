linking_pipeline:
  domain: "beverlyhillscop"

  # Toggle multi-run behavior
  run_all_levels: true
  levels: ["paragraph"]
  level: "paragraph"  # used when run_all_levels=false

  run_all_variants: true
  retrieval_variants:
    - "lead_paragraph"
    - "full_text"
  retrieval_variant: "lead_paragraph"  # used when run_all_variants=false

  data_dir: "data/processed/${domain}"
  output_dir: "outputs/linking_pipeline/${domain}"

  seed: 42

  max_examples: 0
  top_k: 10
  include_scores: true

  use_cached_spans: true
  span_cache_path: "data/processed/${domain}/span_cache_{level}.jsonl"

  # Query construction
  query:
    mode: "context_anchor"  # context_anchor | anchor_only | full_text
    context_window: 200

  evaluation:
    max_error_samples: 200

  # Span identification model
  span_model:
    # Default path matches existing span_id training output layout
    model_dir: "data/processed/${domain}/models/${domain}/checkpoint-10520"
    model_name: "bert-base-uncased"
    normalize_punctuation: false
    max_seq_length: 512
    stride: 128

  # Retrieval backends
  retrieval:
    article_classifier:
      ckpt_path: "outputs/retrieval/${domain}/minilm-l6/best_model.pt"
      max_length: 256

    article_faiss:
      index_dir: "outputs/retrieval/${domain}/faiss"
      retriever_ckpt: "outputs/retrieval/${domain}/minilm-l6/best_model.pt"
      encoder_name: "sentence-transformers/all-MiniLM-L6-v2"
      max_length: 256
      normalize: true

    paragraph_faiss:
      index_root: "outputs/retrieval/${domain}/paragraph_faiss_minilm-l6"
      model_name: "sentence-transformers/all-MiniLM-L6-v2"
      paragraphs_csv: "data/processed/${domain}/paragraphs_${domain}.csv"
      paragraph_id_field: "paragraph_id"
      max_length: 256
      normalize: true
